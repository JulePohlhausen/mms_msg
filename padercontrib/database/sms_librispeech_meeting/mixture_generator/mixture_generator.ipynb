{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9219a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35790357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paderbox as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "def plot_meeting(ex):\n",
    "    with pb.visualization.axes_context(columns=1, figure_size=(10, 3)) as ac:\n",
    "        activity = defaultdict(pb.array.interval.zeros)\n",
    "        speech_activity = defaultdict(pb.array.interval.zeros)\n",
    "        try:\n",
    "            num_samples = pb.utils.nested.get_by_path(ex, 'num_samples.original_source', allow_early_stopping=True)\n",
    "        except KeyError:\n",
    "            num_samples = pb.utils.nested.get_by_path(ex, 'num_samples.speech_source', allow_early_stopping=True)\n",
    "        for o, l, s,  in zip(ex['offset'], num_samples, ex['speaker_id']):\n",
    "            speech_activity[s][o:o+l]=True\n",
    "\n",
    "        pb.visualization.plot.activity(speech_activity, ax=ac.new)\n",
    "        \n",
    "def plot_meetings(generator_dataset, number=6, columns=3, figure_width=10):\n",
    "    with pb.visualization.axes_context(columns=columns, figure_size=(figure_width, 3)) as ac:\n",
    "        for ex in itertools.islice(generator_dataset, number):\n",
    "            activity = defaultdict(pb.array.interval.zeros)\n",
    "            try:\n",
    "                num_samples = pb.utils.nested.get_by_path(ex, 'num_samples.original_source', allow_early_stopping=True)\n",
    "            except KeyError:\n",
    "                num_samples = pb.utils.nested.get_by_path(ex, 'num_samples.speech_source', allow_early_stopping=True)\n",
    "            for o, l, s in zip(ex['offset'], num_samples, ex['speaker_id']):\n",
    "                activity[s][o:o+l] = True\n",
    "\n",
    "            pb.visualization.plot.activity(activity, ax=ac.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66df988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from padercontrib.database.sms_librispeech_meeting import mixture_generator as g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffcab8",
   "metadata": {},
   "source": [
    "## Preparation: Prepare input dataset\n",
    "The mixture/meeting generators are generic, i.e., they work with any database that contains examples of single-speaker speech.\n",
    "The input database has to have its examples in the correct format, i.e., they have to contain the correct keys.\n",
    "\n",
    "The examples have to have the following format:\n",
    " - `example_id` (`str`): The ID of the input example. Has to be unique in the input dataset\n",
    " - `num_samples` (`int`): The number of samples in the example\n",
    " - `speaker_id` (`str`): The ID of the speaker that uttered the speech in this example\n",
    " - `audio_path.observation` (`str`): The path to the audio, will later be in `audio_path.original_source` (**TODO: this is not used by the generator, but just copied. Do we want to have this mandatory?**)\n",
    " \n",
    "For meeting data additionally:\n",
    " - `scenario` (`str`): An identifier that uniquely identifies a \"scenario\" that should not change for a single speaker in a meeting. E.g., in LibriSpeech the scenario should be `f\"{chapter_id}_{speaker_id}\"`\n",
    "\n",
    "All other keys are simply copied over from the input examples, so all information present in the input examples will be present in the generated mixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input datasets\n",
    "from padercontrib.database.wsj import WSJ_8kHz\n",
    "db = WSJ_8kHz()\n",
    "dataset_name = 'test_eval92'\n",
    "\n",
    "def wsj_format_fn(example):\n",
    "    example['num_samples'] = example['num_samples']['observation']\n",
    "    example['scenario'] = example['speaker_id']\n",
    "    return example\n",
    "\n",
    "input_ds = db.get_dataset(dataset_name).map(wsj_format_fn)\n",
    "\n",
    "# If we want to have reverberation, prepare the RIR dataset\n",
    "rir_ds = g.rir_dataset_from_scenarios('/net/db/sms_wsj/rirs/scenarios.json', dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08255c7d",
   "metadata": {},
   "source": [
    "## Fully overlapped mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic, anechoic\n",
    "# TODO: num_spekaers -> list\n",
    "\n",
    "# Compute a composition of base examples. This makes sure that the speaker distribution\n",
    "# in the mixtures is equal to the speaker distribution in the original database.\n",
    "ds = g.get_composition_dataset(input_dataset=input_ds, num_speakers=2)\n",
    "\n",
    "# If required: Offset the utterances\n",
    "ds = ds.map(g.ConstantOffsetSampler())\n",
    "\n",
    "# If required: Add log_weights to simulate volume differences\n",
    "ds = ds.map(g.UniformLogWeightSampler(max_weight=5))\n",
    "\n",
    "len(ds), ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98943710",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_meetings(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic, anechoic, no offset, like WSJ0-2mix\n",
    "# TODO: num_spekaers -> list\n",
    "\n",
    "# Compute a composition of base examples. This makes sure that the speaker distribution\n",
    "# in the mixtures is equal to the speaker distribution in the original database.\n",
    "ds = g.get_composition_dataset(input_dataset=input_ds, num_speakers=2)\n",
    "\n",
    "# If required: Offset the utterances\n",
    "ds = ds.map(g.ConstantOffsetSampler(0))\n",
    "\n",
    "# If required: Add log_weights to simulate volume differences\n",
    "ds = ds.map(g.UniformLogWeightSampler(max_weight=5))\n",
    "\n",
    "len(ds), ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_meetings(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d261d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If required: Add reverberation\n",
    "ds = ds.map(g.RIRSampler(rir_ds))\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c67d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example\n",
    "from padercontrib.database.sms_librispeech_meeting.scenario import multi_channel_scenario_map_fn\n",
    "def load_audio(example):\n",
    "    example['audio_data'] = pb.io.audioread.recursive_load_audio(example['audio_path'])\n",
    "    return example\n",
    "ds = ds.map(load_audio)\n",
    "ds = ds.map(multi_channel_scenario_map_fn)\n",
    "ex = ds[0]\n",
    "pb.io.play(ex['audio_data']['observation'], sample_rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic mixing: Set the rng argument to `True` to get a non-deterministic dataset that changes its contents \n",
    "# every time it is iterated. Useful if you want to train on an infinite stream of randomly generated examples\n",
    "# TODO: dynamic_ -> rng\n",
    "ds = g.get_composition_dataset(input_dataset=input_ds, num_speakers=2, rng=True)\n",
    "# only the function above this line changed from the determinstic case\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# the part below this line is deterministic and equal to the cell above\n",
    "ds = ds.map(g.SMSWSJOffsetSampler())\n",
    "ds = ds.map(g.UniformLogWeightSampler(max_weight=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b968ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that iterating two times gives different examples\n",
    "for _ in range(2):\n",
    "    for e in ds:\n",
    "        print(e)\n",
    "        print()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd901e0",
   "metadata": {},
   "source": [
    "## Generate Meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef6da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic, anechoic, use the same base function as for SMS-WSJ, i.e., we have the same initial examples as SMS-WSJ\n",
    "ds = g.get_composition_dataset(input_dataset=input_ds, num_speakers=[3, 4, 5])\n",
    "ds = ds.map(g.UniformLogWeightSampler(max_weight=5))\n",
    "ds = ds.map(g.MeetingSampler(duration=60*8000)(input_ds))\n",
    "# len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bee328",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_meetings(ds, columns=2, figure_width=20, number=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62be343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic, anechoic, use the same base function as for SMS-WSJ, i.e., we have the same initial examples as SMS-WSJ\n",
    "import functools\n",
    "ds = g.get_composition_dataset(input_dataset=input_ds, num_speakers=[3, 4])\n",
    "ds = ds.map(g.UniformLogWeightSampler(max_weight=5))\n",
    "ds = ds.map(functools.partial(g.RIRSampler(rir_ds)))\n",
    "ds = ds.map(g.MeetingSampler(duration=60*8000)(input_ds))\n",
    "# len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librispeech, this takes a long time to load the VAD information\n",
    "from padercontrib.database.librispeech import LibriSpeech\n",
    "\n",
    "db = LibriSpeech()\n",
    "\n",
    "# Map scenario: scenario is composed of speaker-ID and chapter-ID because the environment changes heavily between chapters\n",
    "def format_fn(example):\n",
    "    example['scenario'] = example['speaker_id'] + '_' + example['chapter_id']\n",
    "    return example\n",
    "\n",
    "librispeech_input_ds = db.get_dataset('test_clean').map(format_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "librispeech_input_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is exactly the same as for WSJ, except for the input dataset and some config\n",
    "# TODO: rng arg (int or bool), random sart seed for dynamic mixing\n",
    "ds = g.get_composition_dataset(input_dataset=librispeech_input_ds, num_speakers=(5, 8))\n",
    "ds = ds.map(g.UniformLogWeightSampler())\n",
    "ds = ds.map(g.MeetingSampler(600*8000)(librispeech_input_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e373f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_meetings(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d35c4",
   "metadata": {},
   "source": [
    "## Class-based interface idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = g.wsj_full_overlap.WSJ8_kHz_FullOverlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e16984",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get_dataset('cv_dev93')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9e6b1",
   "metadata": {},
   "source": [
    "## Generate JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72901ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "database_dict = {'datasets': {dataset_name: dict(tqdm(db.get_dataset(dataset_name).items(), desc=dataset_name)) for dataset_name in db.dataset_names}}\n",
    "pb.io.dump(database_dict, 'wsj_full_overlap.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528278dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (padertorch)",
   "language": "python",
   "name": "padertorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
